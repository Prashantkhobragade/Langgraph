{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langgraph\n",
      "  Downloading langgraph-0.2.14-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting langchain-core<0.3,>=0.2.27 (from langgraph)\n",
      "  Downloading langchain_core-0.2.35-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting langgraph-checkpoint<2.0.0,>=1.0.2 (from langgraph)\n",
      "  Downloading langgraph_checkpoint-1.0.6-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain-core<0.3,>=0.2.27->langgraph)\n",
      "  Using cached PyYAML-6.0.2-cp312-cp312-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3,>=0.2.27->langgraph)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.75 (from langchain-core<0.3,>=0.2.27->langgraph)\n",
      "  Downloading langsmith-0.1.104-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\pkhobragade\\desktop\\langgraph\\langgraph\\langg\\lib\\site-packages (from langchain-core<0.3,>=0.2.27->langgraph) (24.1)\n",
      "Collecting pydantic<3,>=1 (from langchain-core<0.3,>=0.2.27->langgraph)\n",
      "  Using cached pydantic-2.8.2-py3-none-any.whl.metadata (125 kB)\n",
      "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain-core<0.3,>=0.2.27->langgraph)\n",
      "  Using cached tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting typing-extensions>=4.7 (from langchain-core<0.3,>=0.2.27->langgraph)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.27->langgraph)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.27->langgraph)\n",
      "  Using cached httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.27->langgraph)\n",
      "  Using cached orjson-3.10.7-cp312-none-win_amd64.whl.metadata (51 kB)\n",
      "Collecting requests<3,>=2 (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.27->langgraph)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1->langchain-core<0.3,>=0.2.27->langgraph)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.20.1 (from pydantic<3,>=1->langchain-core<0.3,>=0.2.27->langgraph)\n",
      "  Using cached pydantic_core-2.20.1-cp312-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Collecting anyio (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.27->langgraph)\n",
      "  Using cached anyio-4.4.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting certifi (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.27->langgraph)\n",
      "  Using cached certifi-2024.7.4-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.27->langgraph)\n",
      "  Using cached httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting idna (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.27->langgraph)\n",
      "  Downloading idna-3.8-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting sniffio (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.27->langgraph)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.27->langgraph)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.27->langgraph)\n",
      "  Using cached charset_normalizer-3.3.2-cp312-cp312-win_amd64.whl.metadata (34 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.27->langgraph)\n",
      "  Using cached urllib3-2.2.2-py3-none-any.whl.metadata (6.4 kB)\n",
      "Downloading langgraph-0.2.14-py3-none-any.whl (87 kB)\n",
      "   ---------------------------------------- 0.0/87.7 kB ? eta -:--:--\n",
      "   ---- ----------------------------------- 10.2/87.7 kB ? eta -:--:--\n",
      "   -------------- ------------------------- 30.7/87.7 kB 435.7 kB/s eta 0:00:01\n",
      "   -------------- ------------------------- 30.7/87.7 kB 435.7 kB/s eta 0:00:01\n",
      "   -------------- ------------------------- 30.7/87.7 kB 435.7 kB/s eta 0:00:01\n",
      "   ------------------ --------------------- 41.0/87.7 kB 178.6 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 81.9/87.7 kB 305.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 87.7/87.7 kB 291.1 kB/s eta 0:00:00\n",
      "Downloading langchain_core-0.2.35-py3-none-any.whl (394 kB)\n",
      "   ---------------------------------------- 0.0/394.9 kB ? eta -:--:--\n",
      "   ---- ---------------------------------- 41.0/394.9 kB 991.0 kB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 112.6/394.9 kB 1.3 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 112.6/394.9 kB 1.3 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 112.6/394.9 kB 1.3 MB/s eta 0:00:01\n",
      "   -------------- ----------------------- 153.6/394.9 kB 706.2 kB/s eta 0:00:01\n",
      "   --------------------- ---------------- 225.3/394.9 kB 860.2 kB/s eta 0:00:01\n",
      "   ---------------------- --------------- 235.5/394.9 kB 846.9 kB/s eta 0:00:01\n",
      "   ---------------------- --------------- 235.5/394.9 kB 846.9 kB/s eta 0:00:01\n",
      "   --------------------------- ---------- 286.7/394.9 kB 681.0 kB/s eta 0:00:01\n",
      "   -------------------------------- ----- 337.9/394.9 kB 749.8 kB/s eta 0:00:01\n",
      "   -------------------------------------- 394.9/394.9 kB 794.8 kB/s eta 0:00:00\n",
      "Downloading langgraph_checkpoint-1.0.6-py3-none-any.whl (15 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langsmith-0.1.104-py3-none-any.whl (149 kB)\n",
      "   ---------------------------------------- 0.0/149.1 kB ? eta -:--:--\n",
      "   -------------------------------- ------- 122.9/149.1 kB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 149.1/149.1 kB 3.0 MB/s eta 0:00:00\n",
      "Using cached pydantic-2.8.2-py3-none-any.whl (423 kB)\n",
      "Using cached pydantic_core-2.20.1-cp312-none-win_amd64.whl (1.9 MB)\n",
      "Using cached PyYAML-6.0.2-cp312-cp312-win_amd64.whl (156 kB)\n",
      "Using cached tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "Using cached httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached orjson-3.10.7-cp312-none-win_amd64.whl (137 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached certifi-2024.7.4-py3-none-any.whl (162 kB)\n",
      "Using cached charset_normalizer-3.3.2-cp312-cp312-win_amd64.whl (100 kB)\n",
      "Downloading idna-3.8-py3-none-any.whl (66 kB)\n",
      "   ---------------------------------------- 0.0/66.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 66.9/66.9 kB 3.5 MB/s eta 0:00:00\n",
      "Using cached urllib3-2.2.2-py3-none-any.whl (121 kB)\n",
      "Using cached anyio-4.4.0-py3-none-any.whl (86 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: urllib3, typing-extensions, tenacity, sniffio, PyYAML, orjson, jsonpointer, idna, h11, charset-normalizer, certifi, annotated-types, requests, pydantic-core, jsonpatch, httpcore, anyio, pydantic, httpx, langsmith, langchain-core, langgraph-checkpoint, langgraph\n",
      "Successfully installed PyYAML-6.0.2 annotated-types-0.7.0 anyio-4.4.0 certifi-2024.7.4 charset-normalizer-3.3.2 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 idna-3.8 jsonpatch-1.33 jsonpointer-3.0.0 langchain-core-0.2.35 langgraph-0.2.14 langgraph-checkpoint-1.0.6 langsmith-0.1.104 orjson-3.10.7 pydantic-2.8.2 pydantic-core-2.20.1 requests-2.32.3 sniffio-1.3.1 tenacity-8.5.0 typing-extensions-4.12.2 urllib3-2.2.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\pkhobragade\\desktop\\langgraph\\langgraph\\langg\\lib\\site-packages (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.2.14-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langchain_groq\n",
      "  Downloading langchain_groq-0.1.9-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting langchain_community\n",
      "  Using cached langchain_community-0.2.12-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\pkhobragade\\desktop\\langgraph\\langgraph\\langg\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Using cached SQLAlchemy-2.0.32-cp312-cp312-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Downloading aiohttp-3.10.5-cp312-cp312-win_amd64.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.32 in c:\\users\\pkhobragade\\desktop\\langgraph\\langgraph\\langg\\lib\\site-packages (from langchain) (0.2.35)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\pkhobragade\\desktop\\langgraph\\langgraph\\langg\\lib\\site-packages (from langchain) (0.1.104)\n",
      "Collecting numpy<2.0.0,>=1.26.0 (from langchain)\n",
      "  Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\pkhobragade\\desktop\\langgraph\\langgraph\\langg\\lib\\site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\pkhobragade\\desktop\\langgraph\\langgraph\\langg\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\pkhobragade\\desktop\\langgraph\\langgraph\\langg\\lib\\site-packages (from langchain) (8.5.0)\n",
      "Collecting groq<1,>=0.4.1 (from langchain_groq)\n",
      "  Using cached groq-0.9.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiohappyeyeballs-2.4.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached frozenlist-1.4.1-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached multidict-6.0.5-cp312-cp312-win_amd64.whl.metadata (4.3 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached yarl-1.9.4-cp312-cp312-win_amd64.whl.metadata (32 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\pkhobragade\\desktop\\langgraph\\langgraph\\langg\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (4.4.0)\n",
      "Collecting distro<2,>=1.7.0 (from groq<1,>=0.4.1->langchain_groq)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\pkhobragade\\desktop\\langgraph\\langgraph\\langg\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (0.27.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\pkhobragade\\desktop\\langgraph\\langgraph\\langg\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\pkhobragade\\desktop\\langgraph\\langgraph\\langg\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (4.12.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\pkhobragade\\desktop\\langgraph\\langgraph\\langg\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\pkhobragade\\desktop\\langgraph\\langgraph\\langg\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (24.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\pkhobragade\\desktop\\langgraph\\langgraph\\langg\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\pkhobragade\\desktop\\langgraph\\langgraph\\langg\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\pkhobragade\\desktop\\langgraph\\langgraph\\langg\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pkhobragade\\desktop\\langgraph\\langgraph\\langg\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pkhobragade\\desktop\\langgraph\\langgraph\\langg\\lib\\site-packages (from requests<3,>=2->langchain) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pkhobragade\\desktop\\langgraph\\langgraph\\langg\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pkhobragade\\desktop\\langgraph\\langgraph\\langg\\lib\\site-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Using cached greenlet-3.0.3-cp312-cp312-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\pkhobragade\\desktop\\langgraph\\langgraph\\langg\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\pkhobragade\\desktop\\langgraph\\langgraph\\langg\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\pkhobragade\\desktop\\langgraph\\langgraph\\langg\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.32->langchain) (3.0.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading langchain-0.2.14-py3-none-any.whl (997 kB)\n",
      "   ---------------------------------------- 0.0/997.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 10.2/997.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 10.2/997.8 kB ? eta -:--:--\n",
      "   - ------------------------------------- 30.7/997.8 kB 217.9 kB/s eta 0:00:05\n",
      "   - ------------------------------------- 30.7/997.8 kB 217.9 kB/s eta 0:00:05\n",
      "   - ------------------------------------- 41.0/997.8 kB 163.4 kB/s eta 0:00:06\n",
      "   -- ------------------------------------ 61.4/997.8 kB 218.8 kB/s eta 0:00:05\n",
      "   --- ----------------------------------- 92.2/997.8 kB 291.5 kB/s eta 0:00:04\n",
      "   --- ----------------------------------- 92.2/997.8 kB 291.5 kB/s eta 0:00:04\n",
      "   ---- --------------------------------- 122.9/997.8 kB 300.4 kB/s eta 0:00:03\n",
      "   ----- -------------------------------- 153.6/997.8 kB 339.7 kB/s eta 0:00:03\n",
      "   ------- ------------------------------ 194.6/997.8 kB 406.9 kB/s eta 0:00:02\n",
      "   -------- ----------------------------- 235.5/997.8 kB 436.6 kB/s eta 0:00:02\n",
      "   --------- ---------------------------- 245.8/997.8 kB 418.3 kB/s eta 0:00:02\n",
      "   ---------- --------------------------- 276.5/997.8 kB 437.2 kB/s eta 0:00:02\n",
      "   ------------ ------------------------- 327.7/997.8 kB 483.9 kB/s eta 0:00:02\n",
      "   ------------- ------------------------ 348.2/997.8 kB 502.9 kB/s eta 0:00:02\n",
      "   ------------- ------------------------ 358.4/997.8 kB 484.2 kB/s eta 0:00:02\n",
      "   --------------- ---------------------- 399.4/997.8 kB 498.2 kB/s eta 0:00:02\n",
      "   --------------- ---------------------- 399.4/997.8 kB 498.2 kB/s eta 0:00:02\n",
      "   --------------- ---------------------- 399.4/997.8 kB 498.2 kB/s eta 0:00:02\n",
      "   --------------- ---------------------- 399.4/997.8 kB 498.2 kB/s eta 0:00:02\n",
      "   --------------- ---------------------- 399.4/997.8 kB 498.2 kB/s eta 0:00:02\n",
      "   -------------------------- ----------- 686.1/997.8 kB 665.2 kB/s eta 0:00:01\n",
      "   --------------------------- ---------- 727.0/997.8 kB 664.9 kB/s eta 0:00:01\n",
      "   ------------------------------- ------ 829.4/997.8 kB 738.7 kB/s eta 0:00:01\n",
      "   -------------------------------- ----- 860.2/997.8 kB 735.2 kB/s eta 0:00:01\n",
      "   --------------------------------- ---- 890.9/997.8 kB 741.3 kB/s eta 0:00:01\n",
      "   ----------------------------------- -- 942.1/997.8 kB 736.0 kB/s eta 0:00:01\n",
      "   -------------------------------------  993.3/997.8 kB 757.9 kB/s eta 0:00:01\n",
      "   -------------------------------------- 997.8/997.8 kB 743.6 kB/s eta 0:00:00\n",
      "Downloading langchain_groq-0.1.9-py3-none-any.whl (14 kB)\n",
      "Using cached langchain_community-0.2.12-py3-none-any.whl (2.3 MB)\n",
      "Downloading aiohttp-3.10.5-cp312-cp312-win_amd64.whl (377 kB)\n",
      "   ---------------------------------------- 0.0/377.6 kB ? eta -:--:--\n",
      "   ------------- -------------------------- 122.9/377.6 kB 7.0 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 204.8/377.6 kB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 235.5/377.6 kB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 235.5/377.6 kB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 235.5/377.6 kB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 348.2/377.6 kB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 377.6/377.6 kB 1.2 MB/s eta 0:00:00\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached groq-0.9.0-py3-none-any.whl (103 kB)\n",
      "Using cached langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
      "Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "Using cached SQLAlchemy-2.0.32-cp312-cp312-win_amd64.whl (2.1 MB)\n",
      "Downloading aiohappyeyeballs-2.4.0-py3-none-any.whl (12 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached frozenlist-1.4.1-cp312-cp312-win_amd64.whl (50 kB)\n",
      "Using cached greenlet-3.0.3-cp312-cp312-win_amd64.whl (293 kB)\n",
      "Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
      "   ---------------------------------------- 0.0/49.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 49.3/49.3 kB 831.8 kB/s eta 0:00:00\n",
      "Using cached multidict-6.0.5-cp312-cp312-win_amd64.whl (27 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached yarl-1.9.4-cp312-cp312-win_amd64.whl (76 kB)\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: numpy, mypy-extensions, multidict, marshmallow, greenlet, frozenlist, distro, attrs, aiohappyeyeballs, yarl, typing-inspect, SQLAlchemy, aiosignal, groq, dataclasses-json, aiohttp, langchain-text-splitters, langchain_groq, langchain, langchain_community\n",
      "Successfully installed SQLAlchemy-2.0.32 aiohappyeyeballs-2.4.0 aiohttp-3.10.5 aiosignal-1.3.1 attrs-24.2.0 dataclasses-json-0.6.7 distro-1.9.0 frozenlist-1.4.1 greenlet-3.0.3 groq-0.9.0 langchain-0.2.14 langchain-text-splitters-0.2.2 langchain_community-0.2.12 langchain_groq-0.1.9 marshmallow-3.22.0 multidict-6.0.5 mypy-extensions-1.0.0 numpy-1.26.4 typing-inspect-0.9.0 yarl-1.9.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain_groq langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model = \"llama-3.1-8b-instant\",\n",
    "            temperature=0.0,\n",
    "            groq_api_key = GROQ_API_KEY)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building chatbot using Langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph,START,END\n",
    "from langgraph.graph.message import add_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    # Messages have the type \"list\". The `add_messages` function\n",
    "        # in the annotation defines how this state key should be updated\n",
    "        # (in this case, it appends messages to the list, rather than overwriting them)\n",
    "    messages:Annotated[list,add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(state:State):\n",
    "    return {\"messages\":llm.invoke(state['messages'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.add_node(\"chatbot\",chatbot)\n",
    "graph_builder.add_edge(START,\"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\",END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([{'messages': AIMessage(content='Hello. How can I assist you today?', response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 37, 'total_tokens': 47, 'completion_time': 0.013333333, 'prompt_time': 0.018838712, 'queue_time': 0.247893648, 'total_time': 0.032172045}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_f66ccb39ec', 'finish_reason': 'stop', 'logprobs': None}, id='run-b1b41e28-3be5-42f4-92c2-3f71019d8120-0', usage_metadata={'input_tokens': 37, 'output_tokens': 10, 'total_tokens': 47})}])\n",
      "content='Hello. How can I assist you today?' response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 37, 'total_tokens': 47, 'completion_time': 0.013333333, 'prompt_time': 0.018838712, 'queue_time': 0.247893648, 'total_time': 0.032172045}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_f66ccb39ec', 'finish_reason': 'stop', 'logprobs': None} id='run-b1b41e28-3be5-42f4-92c2-3f71019d8120-0' usage_metadata={'input_tokens': 37, 'output_tokens': 10, 'total_tokens': 47}\n",
      "Assistant: Hello. How can I assist you today?\n",
      "dict_values([{'messages': AIMessage(content=\"Pi (π) is an irrational number that represents the ratio of a circle's circumference to its diameter. It is approximately equal to 3.14159, but its decimal representation goes on forever without repeating.\\n\\nHere are the first 50 digits of pi:\\n\\n3.1415926535897932384626433832795028841971693993751058209749445923078164062862089986280348253421170679\\n\\nPi is a transcendental number, which means it is not a root of any polynomial equation with rational coefficients. This property makes pi an essential constant in mathematics, particularly in geometry and trigonometry.\\n\\nHere are some interesting facts about pi:\\n\\n1. **Pi is an irrational number**: Pi cannot be expressed as a finite decimal or fraction.\\n2. **Pi is a transcendental number**: Pi is not a root of any polynomial equation with rational coefficients.\\n3. **Pi is a universal constant**: Pi is the same for all circles, regardless of their size or location.\\n4. **Pi is a fundamental constant in mathematics**: Pi is used to calculate the area and circumference of circles, as well as the volumes of spheres and cylinders.\\n5. **Pi has been calculated to over 31 trillion digits**: Using advanced computer algorithms and mathematical techniques, mathematicians have calculated pi to over 31 trillion digits.\\n\\nSome common approximations of pi include:\\n\\n* 3.14 (a common approximation used in everyday calculations)\\n* 3.14159 (a more accurate approximation used in many mathematical calculations)\\n* 3.1415926535897932384626433832795028841971693993751058209749445923078164062862089986280348253421170679 (the first 50 digits of pi)\\n\\nKeep in mind that pi is an irrational number, so its decimal representation goes on forever without repeating.\", response_metadata={'token_usage': {'completion_tokens': 378, 'prompt_tokens': 41, 'total_tokens': 419, 'completion_time': 0.504, 'prompt_time': 0.012321195, 'queue_time': 0.085785961, 'total_time': 0.516321195}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_9cb648b966', 'finish_reason': 'stop', 'logprobs': None}, id='run-9d9c2d65-75bd-4545-a916-7512ba388031-0', usage_metadata={'input_tokens': 41, 'output_tokens': 378, 'total_tokens': 419})}])\n",
      "content=\"Pi (π) is an irrational number that represents the ratio of a circle's circumference to its diameter. It is approximately equal to 3.14159, but its decimal representation goes on forever without repeating.\\n\\nHere are the first 50 digits of pi:\\n\\n3.1415926535897932384626433832795028841971693993751058209749445923078164062862089986280348253421170679\\n\\nPi is a transcendental number, which means it is not a root of any polynomial equation with rational coefficients. This property makes pi an essential constant in mathematics, particularly in geometry and trigonometry.\\n\\nHere are some interesting facts about pi:\\n\\n1. **Pi is an irrational number**: Pi cannot be expressed as a finite decimal or fraction.\\n2. **Pi is a transcendental number**: Pi is not a root of any polynomial equation with rational coefficients.\\n3. **Pi is a universal constant**: Pi is the same for all circles, regardless of their size or location.\\n4. **Pi is a fundamental constant in mathematics**: Pi is used to calculate the area and circumference of circles, as well as the volumes of spheres and cylinders.\\n5. **Pi has been calculated to over 31 trillion digits**: Using advanced computer algorithms and mathematical techniques, mathematicians have calculated pi to over 31 trillion digits.\\n\\nSome common approximations of pi include:\\n\\n* 3.14 (a common approximation used in everyday calculations)\\n* 3.14159 (a more accurate approximation used in many mathematical calculations)\\n* 3.1415926535897932384626433832795028841971693993751058209749445923078164062862089986280348253421170679 (the first 50 digits of pi)\\n\\nKeep in mind that pi is an irrational number, so its decimal representation goes on forever without repeating.\" response_metadata={'token_usage': {'completion_tokens': 378, 'prompt_tokens': 41, 'total_tokens': 419, 'completion_time': 0.504, 'prompt_time': 0.012321195, 'queue_time': 0.085785961, 'total_time': 0.516321195}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_9cb648b966', 'finish_reason': 'stop', 'logprobs': None} id='run-9d9c2d65-75bd-4545-a916-7512ba388031-0' usage_metadata={'input_tokens': 41, 'output_tokens': 378, 'total_tokens': 419}\n",
      "Assistant: Pi (π) is an irrational number that represents the ratio of a circle's circumference to its diameter. It is approximately equal to 3.14159, but its decimal representation goes on forever without repeating.\n",
      "\n",
      "Here are the first 50 digits of pi:\n",
      "\n",
      "3.1415926535897932384626433832795028841971693993751058209749445923078164062862089986280348253421170679\n",
      "\n",
      "Pi is a transcendental number, which means it is not a root of any polynomial equation with rational coefficients. This property makes pi an essential constant in mathematics, particularly in geometry and trigonometry.\n",
      "\n",
      "Here are some interesting facts about pi:\n",
      "\n",
      "1. **Pi is an irrational number**: Pi cannot be expressed as a finite decimal or fraction.\n",
      "2. **Pi is a transcendental number**: Pi is not a root of any polynomial equation with rational coefficients.\n",
      "3. **Pi is a universal constant**: Pi is the same for all circles, regardless of their size or location.\n",
      "4. **Pi is a fundamental constant in mathematics**: Pi is used to calculate the area and circumference of circles, as well as the volumes of spheres and cylinders.\n",
      "5. **Pi has been calculated to over 31 trillion digits**: Using advanced computer algorithms and mathematical techniques, mathematicians have calculated pi to over 31 trillion digits.\n",
      "\n",
      "Some common approximations of pi include:\n",
      "\n",
      "* 3.14 (a common approximation used in everyday calculations)\n",
      "* 3.14159 (a more accurate approximation used in many mathematical calculations)\n",
      "* 3.1415926535897932384626433832795028841971693993751058209749445923078164062862089986280348253421170679 (the first 50 digits of pi)\n",
      "\n",
      "Keep in mind that pi is an irrational number, so its decimal representation goes on forever without repeating.\n",
      "dict_values([{'messages': AIMessage(content='As of my cut-off knowledge in December 2023, the Prime Minister of Australia is Anthony Albanese.', response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 42, 'total_tokens': 65, 'completion_time': 0.030666667, 'prompt_time': 0.010712895, 'queue_time': 0.045654175, 'total_time': 0.041379562}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_f66ccb39ec', 'finish_reason': 'stop', 'logprobs': None}, id='run-92f4d9b3-366c-4519-a2ba-7d1ff1a473cd-0', usage_metadata={'input_tokens': 42, 'output_tokens': 23, 'total_tokens': 65})}])\n",
      "content='As of my cut-off knowledge in December 2023, the Prime Minister of Australia is Anthony Albanese.' response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 42, 'total_tokens': 65, 'completion_time': 0.030666667, 'prompt_time': 0.010712895, 'queue_time': 0.045654175, 'total_time': 0.041379562}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_f66ccb39ec', 'finish_reason': 'stop', 'logprobs': None} id='run-92f4d9b3-366c-4519-a2ba-7d1ff1a473cd-0' usage_metadata={'input_tokens': 42, 'output_tokens': 23, 'total_tokens': 65}\n",
      "Assistant: As of my cut-off knowledge in December 2023, the Prime Minister of Australia is Anthony Albanese.\n",
      "Good Bye\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    if user_input.lower() in ['quit','q']:\n",
    "        print(\"Good Bye\")\n",
    "        break\n",
    "    for event in graph.stream({'messages':(\"user\", user_input)}):\n",
    "        print(event.values())\n",
    "        for value in event.values():\n",
    "            print(value['messages'])\n",
    "            print(\"Assistant:\",value['messages'].content)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Multi Agent system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import (\n",
    "    BaseMessage,\n",
    "    HumanMessage,\n",
    "    ToolMessage,\n",
    ")\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "\n",
    "def create_agent(llm, tools, system_message: str):\n",
    "    \"\"\"Create an agent.\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"You are a helpful AI assistant, collaborating with other assistants.\"\n",
    "                \" Use the provided tools to progress towards answering the question.\"\n",
    "                \" If you are unable to fully answer, that's OK, another assistant with different tools \"\n",
    "                \" will help where you left off. Execute what you can to make progress.\"\n",
    "                \" If you or any of the other assistants have the final answer or deliverable,\"\n",
    "                \" prefix your response with FINAL ANSWER so the team knows to stop.\"\n",
    "                \" You have access to the following tools: {tool_names}.\\n{system_message}\",\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        ]\n",
    "    )\n",
    "    prompt = prompt.partial(system_message=system_message)\n",
    "    prompt = prompt.partial(tool_names=\", \".join([tool.name for tool in tools]))\n",
    "    return prompt | llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "#from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.tools import tool\n",
    "#from langchain_experimental.utilities import PythonREPL\n",
    "\n",
    "#tavily_tool = TavilySearchResults(max_results=5)\n",
    "\n",
    "# Warning: This executes code locally, which can be unsafe when not sandboxed\n",
    "\n",
    "#repl = PythonREPL()\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "@tool\n",
    "def addition(a: int, b: int) -> float:\n",
    "    \"if mathmetic operator is + (addition), you do division\"\n",
    "    return a//b\n",
    "\n",
    "@tool\n",
    "def division(a: int, b: int) -> float:\n",
    "    \"if mathmetical operation is // (floor division), you do addition\"\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, Sequence, TypedDict\n",
    "\n",
    "#from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# This defines the object that is passed between each node\n",
    "# in the graph. We will create different nodes for each agent and tool\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    sender: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "\n",
    "# Helper function to create a node for a given agent\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    # We convert the agent output into a format that is suitable to append to the global state\n",
    "    if isinstance(result, ToolMessage):\n",
    "        pass\n",
    "    else:\n",
    "        result = AIMessage(**result.dict(exclude={\"type\", \"name\"}), name=name)\n",
    "    return {\n",
    "        \"messages\": [result],\n",
    "        # Since we have a strict workflow, we can\n",
    "        # track the sender so we know who to pass to next.\n",
    "        \"sender\": name,\n",
    "    }\n",
    "\n",
    "\n",
    "llm = ChatGroq(model = \"llama-3.1-8b-instant\",\n",
    "            temperature=0.0,\n",
    "            groq_api_key = GROQ_API_KEY)\n",
    "\n",
    "# Multiply agent and node\n",
    "Multiply_agent = create_agent(\n",
    "    llm,\n",
    "    [multiply],\n",
    "    system_message=\"You should provide accurate result\",\n",
    ")\n",
    "multi_node = functools.partial(agent_node, agent=Multiply_agent, name=\"Multiplying Agent\")\n",
    "\n",
    "# addition\n",
    "add_agent = create_agent(\n",
    "    llm,\n",
    "    [addition],\n",
    "    system_message=\"You Should Provide accurate result.\",\n",
    ")\n",
    "add_node = functools.partial(agent_node, agent=add_agent, name=\"addition agent\")\n",
    "\n",
    "#division\n",
    "divi_agent = create_agent(\n",
    "    llm,\n",
    "    [division],\n",
    "    system_message=\"You should provide accurate result\",\n",
    ")\n",
    "\n",
    "divi_node = functools.partial(agent_node, agent=divi_agent, name=\"division agent\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_core in c:\\users\\pkhobragade\\desktop\\langgraph\\langgraph\\langg\\lib\\site-packages (0.2.35)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\pkhobragade\\desktop\\langgraph\\langgraph\\langg\\lib\\site-packages (from langchain_core) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\pkhobragade\\desktop\\langgraph\\langgraph\\langg\\lib\\site-packages (from langchain_core) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in c:\\users\\pkhobragade\\desktop\\langgraph\\langgraph\\langg\\lib\\site-packages (from langchain_core) (0.1.104)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\pkhobragade\\desktop\\langgraph\\langgraph\\langg\\lib\\site-packages (from langchain_core) (24.1)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\pkhobragade\\desktop\\langgraph\\langgraph\\langg\\lib\\site-packages (from langchain_core) (2.8.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\pkhobragade\\desktop\\langgraph\\langgraph\\langg\\lib\\site-packages (from langchain_core) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\pkhobragade\\desktop\\langgraph\\langgraph\\langg\\lib\\site-packages (from langchain_core) (4.12.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\pkhobragade\\desktop\\langgraph\\langgraph\\langg\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain_core) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\pkhobragade\\desktop\\langgraph\\langgraph\\langg\\lib\\site-packages (from langsmith<0.2.0,>=0.1.75->langchain_core) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\pkhobragade\\desktop\\langgraph\\langgraph\\langg\\lib\\site-packages (from langsmith<0.2.0,>=0.1.75->langchain_core) (3.10.7)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\pkhobragade\\desktop\\langgraph\\langgraph\\langg\\lib\\site-packages (from langsmith<0.2.0,>=0.1.75->langchain_core) (2.32.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\pkhobragade\\desktop\\langgraph\\langgraph\\langg\\lib\\site-packages (from pydantic<3,>=1->langchain_core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\pkhobragade\\desktop\\langgraph\\langgraph\\langg\\lib\\site-packages (from pydantic<3,>=1->langchain_core) (2.20.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\pkhobragade\\desktop\\langgraph\\langgraph\\langg\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain_core) (4.4.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\pkhobragade\\desktop\\langgraph\\langgraph\\langg\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain_core) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\pkhobragade\\desktop\\langgraph\\langgraph\\langg\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain_core) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\pkhobragade\\desktop\\langgraph\\langgraph\\langg\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain_core) (3.8)\n",
      "Requirement already satisfied: sniffio in c:\\users\\pkhobragade\\desktop\\langgraph\\langgraph\\langg\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain_core) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\pkhobragade\\desktop\\langgraph\\langgraph\\langg\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain_core) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pkhobragade\\desktop\\langgraph\\langgraph\\langg\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain_core) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pkhobragade\\desktop\\langgraph\\langgraph\\langg\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain_core) (2.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Too many arguments for tool decorator",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#from langchain_core.tools import create_tool \u001b[39;00m\n\u001b[0;32m      4\u001b[0m tools \u001b[38;5;241m=\u001b[39m [Multiply_agent, add_agent, divi_agent]\n\u001b[1;32m----> 5\u001b[0m tool_node \u001b[38;5;241m=\u001b[39m \u001b[43mToolNode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pkhobragade\\Desktop\\Langgraph\\Langgraph\\langg\\Lib\\site-packages\\langgraph\\prebuilt\\tool_node.py:81\u001b[0m, in \u001b[0;36mToolNode.__init__\u001b[1;34m(self, tools, name, tags, handle_tool_errors)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tool_ \u001b[38;5;129;01min\u001b[39;00m tools:\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tool_, BaseTool):\n\u001b[1;32m---> 81\u001b[0m         tool_ \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_tool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtools_by_name[tool_\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m tool_\n",
      "File \u001b[1;32mc:\\Users\\pkhobragade\\Desktop\\Langgraph\\Langgraph\\langg\\Lib\\site-packages\\langchain_core\\tools\\convert.py:224\u001b[0m, in \u001b[0;36mtool\u001b[1;34m(return_direct, args_schema, infer_schema, response_format, parse_docstring, error_on_invalid_docstring, *args)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _partial\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mToo many arguments for tool decorator\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Too many arguments for tool decorator"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "#from langchain_core.tools import create_tool \n",
    "\n",
    "tools = [Multiply_agent, add_agent, divi_agent]\n",
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
